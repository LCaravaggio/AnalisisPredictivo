{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEBi8h+glUb1zV+k2WEPcL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/AnalisisPredictivo/blob/master/Kaggle/2025Q1/TabNet_para_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74M1tAn1218V",
        "outputId": "a35c8ea0-b7ca-4fda-aebf-6b09a590e94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading analisis-predictivo-2025-q-1.zip to /content\n",
            "\r  0% 0.00/13.6M [00:00<?, ?B/s]\n",
            "\r100% 13.6M/13.6M [00:00<00:00, 451MB/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\n",
        "    'username': userdata.get('KAGGLE_USER'),\n",
        "    'key': userdata.get('KAGGLE_KEY')}\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c analisis-predictivo-2025-q-1\n",
        "\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file.endswith('.zip'):\n",
        "      zip_ref = zipfile.ZipFile(file, 'r')\n",
        "      zip_ref.extractall()\n",
        "      zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar columnas que NO son numéricas\n",
        "df = pd.read_csv('train.csv')\n",
        "non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "print(\"Columnas no numéricas:\")\n",
        "print(non_numeric_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8CfWuBTHJ9i",
        "outputId": "f2ac1265-3477-4f2d-e018-20a249d90433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas no numéricas:\n",
            "Index(['well_name', 'location', 'technology_level'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Cargar los datos\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Columnas categóricas a codificar\n",
        "cat_cols = ['location', 'technology_level']\n",
        "\n",
        "# Codificar esas columnas\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "df[cat_cols] = encoder.fit_transform(df[cat_cols])\n",
        "\n",
        "# Seleccionar solo columnas numéricas\n",
        "df = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Separar X (features) e y (target)\n",
        "X = df.drop(columns='production_rate')\n",
        "y = df['production_rate']\n",
        "\n",
        "# Hacer el split en 80% entrenamiento y 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "gzCsH-M95GRj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBuw-_I853I5",
        "outputId": "e20d2e5e-4145-45de-ee70-6da972ef60cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3->pytorch-tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m834.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "import torch\n",
        "\n",
        "reg = TabNetRegressor(\n",
        "    n_d=24,\n",
        "    n_a=24,\n",
        "    n_steps=5,\n",
        "    gamma=1.5,\n",
        "    lambda_sparse=1e-5,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.95},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='sparsemax',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "\n",
        "reg.fit(\n",
        "    X_train.values, y_train.values.reshape(-1, 1),\n",
        "    eval_set=[(X_test.values, y_test.values.reshape(-1, 1))],\n",
        "    max_epochs=200,\n",
        "    patience=20,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqs81s6T4slw",
        "outputId": "06068c93-b298-4d71-ad95-ebbfd2f3ec58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 546034852702.0505| val_0_mse: 547979680700.9423|  0:00:04s\n",
            "epoch 1  | loss: 545855236230.8529| val_0_mse: 547749766467.3774|  0:00:08s\n",
            "epoch 2  | loss: 545389651850.7914| val_0_mse: 547097213897.47217|  0:00:17s\n",
            "epoch 3  | loss: 544611587023.47815| val_0_mse: 545985505758.61816|  0:00:24s\n",
            "epoch 4  | loss: 543432911174.4197| val_0_mse: 544500031914.78125|  0:00:28s\n",
            "epoch 5  | loss: 541946216770.6388| val_0_mse: 542903187628.226|  0:00:31s\n",
            "epoch 6  | loss: 540177153896.76306| val_0_mse: 540928467736.7252|  0:00:35s\n",
            "epoch 7  | loss: 538146548320.72864| val_0_mse: 538524954691.95776|  0:00:39s\n",
            "epoch 8  | loss: 535973810788.5095| val_0_mse: 536698600035.6448|  0:00:42s\n",
            "epoch 9  | loss: 533670438210.00867| val_0_mse: 534535577302.22943|  0:00:46s\n",
            "epoch 10 | loss: 531138487779.328| val_0_mse: 532429261000.2684|  0:00:50s\n",
            "epoch 11 | loss: 528543473548.0517| val_0_mse: 529961351073.91925|  0:00:53s\n",
            "epoch 12 | loss: 525838632394.1218| val_0_mse: 526608622251.2372|  0:00:57s\n",
            "epoch 13 | loss: 522959533778.7864| val_0_mse: 520843113909.9309|  0:01:00s\n",
            "epoch 14 | loss: 519876036586.5748| val_0_mse: 518629684955.4403|  0:01:04s\n",
            "epoch 15 | loss: 516799970329.8363| val_0_mse: 513910996022.9945|  0:01:07s\n",
            "epoch 16 | loss: 513797349562.5255| val_0_mse: 513653054062.9491|  0:01:11s\n",
            "epoch 17 | loss: 510560316666.17114| val_0_mse: 509470972938.78107|  0:01:15s\n",
            "epoch 18 | loss: 507160837972.59814| val_0_mse: 507617721764.411|  0:01:18s\n",
            "epoch 19 | loss: 503860139695.49786| val_0_mse: 504971778479.4423|  0:01:22s\n",
            "epoch 20 | loss: 500431898824.38885| val_0_mse: 504340190329.8077|  0:01:26s\n",
            "epoch 21 | loss: 496889206044.19946| val_0_mse: 496119593445.5769|  0:01:29s\n",
            "epoch 22 | loss: 492880651777.5754| val_0_mse: 492702582617.23785|  0:01:33s\n",
            "epoch 23 | loss: 488550429077.8191| val_0_mse: 490922960939.6189|  0:01:36s\n",
            "epoch 24 | loss: 484413391584.01965| val_0_mse: 483990710454.1137|  0:01:40s\n",
            "epoch 25 | loss: 480641837069.86346| val_0_mse: 486193632222.7677|  0:01:43s\n",
            "epoch 26 | loss: 476322078029.3514| val_0_mse: 472158930804.8591|  0:01:48s\n",
            "epoch 27 | loss: 471837554023.8178| val_0_mse: 471316839460.8005|  0:01:51s\n",
            "epoch 28 | loss: 467062655488.94525| val_0_mse: 466059473998.2858|  0:01:55s\n",
            "epoch 29 | loss: 462639049453.88306| val_0_mse: 460519383437.0945|  0:01:59s\n",
            "epoch 30 | loss: 458450236644.74585| val_0_mse: 458213026728.7612|  0:02:02s\n",
            "epoch 31 | loss: 454003153376.1773| val_0_mse: 453913426254.37134|  0:02:07s\n",
            "epoch 32 | loss: 449083702126.4345| val_0_mse: 445813548210.4148|  0:02:10s\n",
            "epoch 33 | loss: 444416531688.5268| val_0_mse: 438522781583.05255|  0:02:14s\n",
            "epoch 34 | loss: 439860399843.1705| val_0_mse: 438705458997.36206|  0:02:18s\n",
            "epoch 35 | loss: 435212859413.4252| val_0_mse: 434462308327.12134|  0:02:21s\n",
            "epoch 36 | loss: 430578604683.5791| val_0_mse: 433034691777.59344|  0:02:24s\n",
            "epoch 37 | loss: 425558070324.3028| val_0_mse: 423613149946.74384|  0:02:28s\n",
            "epoch 38 | loss: 420744867913.09784| val_0_mse: 422512016135.29767|  0:02:32s\n",
            "epoch 39 | loss: 416088316646.3212| val_0_mse: 414415436907.62085|  0:02:35s\n",
            "epoch 40 | loss: 411459207823.36| val_0_mse: 406084532295.7937|  0:02:39s\n",
            "epoch 41 | loss: 406991733098.9686| val_0_mse: 398416054324.3301|  0:02:42s\n",
            "epoch 42 | loss: 402411967580.6326| val_0_mse: 396610359017.7027|  0:02:46s\n",
            "epoch 43 | loss: 397597833912.95026| val_0_mse: 397498054629.53754|  0:02:49s\n",
            "epoch 44 | loss: 392624868103.0892| val_0_mse: 380385859116.65753|  0:02:53s\n",
            "epoch 45 | loss: 387876273399.65045| val_0_mse: 380489572931.9036|  0:02:56s\n",
            "epoch 46 | loss: 383389552425.7476| val_0_mse: 367577765593.7091|  0:03:00s\n",
            "epoch 47 | loss: 378784289027.6234| val_0_mse: 381405903009.61|  0:03:04s\n",
            "epoch 48 | loss: 374436755548.0025| val_0_mse: 369125783084.9482|  0:03:07s\n",
            "epoch 49 | loss: 369608711450.93915| val_0_mse: 369518322644.856|  0:03:11s\n",
            "epoch 50 | loss: 364578092190.1687| val_0_mse: 372613579365.21594|  0:03:15s\n",
            "epoch 51 | loss: 359965239924.89355| val_0_mse: 361849632662.45026|  0:03:19s\n",
            "epoch 52 | loss: 354941230746.07263| val_0_mse: 362977277287.08105|  0:03:23s\n",
            "epoch 53 | loss: 350678127174.26215| val_0_mse: 350317419837.42993|  0:03:27s\n",
            "epoch 54 | loss: 346220174487.8671| val_0_mse: 346794623309.4297|  0:03:31s\n",
            "epoch 55 | loss: 341997424758.46893| val_0_mse: 344789134553.9311|  0:03:34s\n",
            "epoch 56 | loss: 337193695626.4763| val_0_mse: 353482075632.1551|  0:03:39s\n",
            "epoch 57 | loss: 332745808039.6209| val_0_mse: 330485240233.9732|  0:03:42s\n",
            "epoch 58 | loss: 327768619271.4042| val_0_mse: 316435473200.0035|  0:03:47s\n",
            "epoch 59 | loss: 322713418586.2695| val_0_mse: 319189862383.46313|  0:03:51s\n",
            "epoch 60 | loss: 318198571920.4627| val_0_mse: 317745656728.7976|  0:03:54s\n",
            "epoch 61 | loss: 313163327874.9145| val_0_mse: 321806380571.606|  0:03:58s\n",
            "epoch 62 | loss: 307874883134.0701| val_0_mse: 321590063172.8033|  0:04:02s\n",
            "epoch 63 | loss: 303239218129.9988| val_0_mse: 312712844342.8615|  0:04:06s\n",
            "epoch 64 | loss: 298570643729.48676| val_0_mse: 294714082878.9597|  0:04:10s\n",
            "epoch 65 | loss: 293856836543.09406| val_0_mse: 281699555550.1521|  0:04:14s\n",
            "epoch 66 | loss: 289175155628.1895| val_0_mse: 284058951321.9747|  0:04:17s\n",
            "epoch 67 | loss: 284246748712.64484| val_0_mse: 277426814096.12933|  0:04:21s\n",
            "epoch 68 | loss: 279436635466.83075| val_0_mse: 269583204629.51447|  0:04:25s\n",
            "epoch 69 | loss: 274487426154.49597| val_0_mse: 269962932253.608|  0:04:29s\n",
            "epoch 70 | loss: 269465996270.98584| val_0_mse: 280935608954.2485|  0:04:35s\n",
            "epoch 71 | loss: 264992289677.9421| val_0_mse: 272890389782.1193|  0:04:39s\n",
            "epoch 72 | loss: 260876101161.90524| val_0_mse: 261063334580.2584|  0:04:43s\n",
            "epoch 73 | loss: 256450634660.6277| val_0_mse: 258970495960.57645|  0:04:47s\n",
            "epoch 74 | loss: 251663172148.61783| val_0_mse: 247004102305.1216|  0:04:51s\n",
            "epoch 75 | loss: 247238259265.22092| val_0_mse: 232098307066.44513|  0:04:55s\n",
            "epoch 76 | loss: 242746494751.66525| val_0_mse: 245164056666.67017|  0:04:59s\n",
            "epoch 77 | loss: 238019248743.03015| val_0_mse: 247733577560.6848|  0:05:02s\n",
            "epoch 78 | loss: 233013627816.40863| val_0_mse: 221873248658.1086|  0:05:06s\n",
            "epoch 79 | loss: 228739905194.4566| val_0_mse: 233498796912.63684|  0:05:10s\n",
            "epoch 80 | loss: 224283309990.51816| val_0_mse: 214137013096.1201|  0:05:14s\n",
            "epoch 81 | loss: 220295055015.936| val_0_mse: 218046230952.09457|  0:05:17s\n",
            "epoch 82 | loss: 215814898883.97784| val_0_mse: 196701912750.3614|  0:05:22s\n",
            "epoch 83 | loss: 211848826000.30524| val_0_mse: 219633449784.78802|  0:05:25s\n",
            "epoch 84 | loss: 207555332770.2646| val_0_mse: 196573022065.30472|  0:05:29s\n",
            "epoch 85 | loss: 203222147974.3803| val_0_mse: 201050093709.57004|  0:05:33s\n",
            "epoch 86 | loss: 198970492009.23572| val_0_mse: 198227484963.93304|  0:05:37s\n",
            "epoch 87 | loss: 195194751751.08917| val_0_mse: 205097380988.84485|  0:05:40s\n",
            "epoch 88 | loss: 191973632265.92493| val_0_mse: 180243966381.04404|  0:05:44s\n",
            "epoch 89 | loss: 188032938319.2419| val_0_mse: 196644103129.99396|  0:05:48s\n",
            "epoch 90 | loss: 184216732182.37045| val_0_mse: 190464785424.1935|  0:05:51s\n",
            "epoch 91 | loss: 180642391624.1526| val_0_mse: 174494431857.67447|  0:05:56s\n",
            "epoch 92 | loss: 177340634345.78708| val_0_mse: 174540436638.48444|  0:05:59s\n",
            "epoch 93 | loss: 173908293552.60062| val_0_mse: 174798011394.84332|  0:06:03s\n",
            "epoch 94 | loss: 170029916175.12366| val_0_mse: 175896319773.74686|  0:06:07s\n",
            "epoch 95 | loss: 166917922780.7114| val_0_mse: 156839456233.0169|  0:06:11s\n",
            "epoch 96 | loss: 163712785237.22824| val_0_mse: 159439395020.45526|  0:06:14s\n",
            "epoch 97 | loss: 160029747828.8935| val_0_mse: 166058912180.89993|  0:06:18s\n",
            "epoch 98 | loss: 156731236508.2782| val_0_mse: 147669035559.19333|  0:06:22s\n",
            "epoch 99 | loss: 154039156645.25793| val_0_mse: 152774091741.22025|  0:06:29s\n",
            "epoch 100| loss: 151321069949.87323| val_0_mse: 165177355704.2549|  0:06:33s\n",
            "epoch 101| loss: 148979674049.61475| val_0_mse: 155980172311.35687|  0:06:36s\n",
            "epoch 102| loss: 146382007193.2849| val_0_mse: 158222258393.56873|  0:06:43s\n",
            "epoch 103| loss: 143750444452.31262| val_0_mse: 144335588887.09268|  0:06:47s\n",
            "epoch 104| loss: 141002536315.98282| val_0_mse: 142101189432.93192|  0:06:51s\n",
            "epoch 105| loss: 138561166271.09418| val_0_mse: 134725201107.67258|  0:06:55s\n",
            "epoch 106| loss: 136507166777.97417| val_0_mse: 163259542983.45135|  0:06:59s\n",
            "epoch 107| loss: 133509510685.30215| val_0_mse: 146037914337.71796|  0:07:03s\n",
            "epoch 108| loss: 130603536290.73721| val_0_mse: 130129199970.47173|  0:07:09s\n",
            "epoch 109| loss: 127966051046.32121| val_0_mse: 113951172296.36134|  0:07:14s\n",
            "epoch 110| loss: 125422852324.1157| val_0_mse: 123889166359.38554|  0:07:19s\n",
            "epoch 111| loss: 122856007467.008| val_0_mse: 120424806892.83875|  0:07:22s\n",
            "epoch 112| loss: 120465995252.9723| val_0_mse: 128526078334.79369|  0:07:26s\n",
            "epoch 113| loss: 118039415342.31631| val_0_mse: 125300441489.4616|  0:07:30s\n",
            "epoch 114| loss: 116334066068.55878| val_0_mse: 121841942499.40224|  0:07:34s\n",
            "epoch 115| loss: 114020589638.57722| val_0_mse: 118112787633.03308|  0:07:38s\n",
            "epoch 116| loss: 111585743526.04555| val_0_mse: 121248565312.26874|  0:07:42s\n",
            "epoch 117| loss: 109550830445.17413| val_0_mse: 106204346906.84158|  0:07:45s\n",
            "epoch 118| loss: 107702513263.22214| val_0_mse: 131186004058.75285|  0:07:49s\n",
            "epoch 119| loss: 105857202958.65108| val_0_mse: 106655411431.19002|  0:07:53s\n",
            "epoch 120| loss: 104041209689.63937| val_0_mse: 117721703854.33025|  0:07:56s\n",
            "epoch 121| loss: 102081545331.31816| val_0_mse: 94131158781.13419|  0:08:01s\n",
            "epoch 122| loss: 100071781045.16924| val_0_mse: 102189566214.22646|  0:08:04s\n",
            "epoch 123| loss: 97910339086.17847| val_0_mse: 103937519107.49808|  0:08:08s\n",
            "epoch 124| loss: 95947017123.36739| val_0_mse: 94754194327.8448|  0:08:12s\n",
            "epoch 125| loss: 93969582008.16246| val_0_mse: 117206381574.28165|  0:08:16s\n",
            "epoch 126| loss: 92132589477.25784| val_0_mse: 89829609477.09573|  0:08:20s\n",
            "epoch 127| loss: 90159635139.0326| val_0_mse: 89527927297.03787|  0:08:24s\n",
            "epoch 128| loss: 88113409410.2843| val_0_mse: 84242470806.62247|  0:08:27s\n",
            "epoch 129| loss: 86293426546.53044| val_0_mse: 102131992097.15723|  0:08:31s\n",
            "epoch 130| loss: 84639955731.69232| val_0_mse: 102594734204.54153|  0:08:35s\n",
            "epoch 131| loss: 82679244798.73969| val_0_mse: 91544352368.1428|  0:08:39s\n",
            "epoch 132| loss: 80738301353.35385| val_0_mse: 88533331233.65364|  0:08:42s\n",
            "epoch 133| loss: 78887043717.2775| val_0_mse: 73092074216.96388|  0:08:47s\n",
            "epoch 134| loss: 77176948371.7711| val_0_mse: 78602553120.51198|  0:08:51s\n",
            "epoch 135| loss: 75629721641.59016| val_0_mse: 84945682347.6822|  0:08:54s\n",
            "epoch 136| loss: 74352275151.00555| val_0_mse: 83083281454.5294|  0:08:58s\n",
            "epoch 137| loss: 72534432261.98648| val_0_mse: 64793789026.75359|  0:09:02s\n",
            "epoch 138| loss: 70828538847.8622| val_0_mse: 81974679911.91214|  0:09:06s\n",
            "epoch 139| loss: 69092434424.1231| val_0_mse: 63772079104.72267|  0:09:10s\n",
            "epoch 140| loss: 67612262571.40185| val_0_mse: 57423200199.31774|  0:09:16s\n",
            "epoch 141| loss: 66127554974.64123| val_0_mse: 64683063420.99469|  0:09:21s\n",
            "epoch 142| loss: 64760877872.67938| val_0_mse: 73632051381.74265|  0:09:27s\n",
            "epoch 143| loss: 63267510976.512| val_0_mse: 56182702267.86462|  0:09:31s\n",
            "epoch 144| loss: 61771660802.83569| val_0_mse: 61490935004.05525|  0:09:35s\n",
            "epoch 145| loss: 60211619269.08061| val_0_mse: 56308819864.6951|  0:09:39s\n",
            "epoch 146| loss: 58844878471.168| val_0_mse: 54966266954.10358|  0:09:43s\n",
            "epoch 147| loss: 57621181245.28246| val_0_mse: 57697225376.20833|  0:09:46s\n",
            "epoch 148| loss: 56430467305.15692| val_0_mse: 62053830823.64156|  0:09:50s\n",
            "epoch 149| loss: 55295092969.15692| val_0_mse: 67104701775.24098|  0:09:54s\n",
            "epoch 150| loss: 54046602400.68923| val_0_mse: 52122437503.82927|  0:09:58s\n",
            "epoch 151| loss: 52717127272.92059| val_0_mse: 55388347656.40903|  0:10:02s\n",
            "epoch 152| loss: 51510766327.96554| val_0_mse: 42121756562.67771|  0:10:06s\n",
            "epoch 153| loss: 50380091812.94279| val_0_mse: 55657347739.70437|  0:10:09s\n",
            "epoch 154| loss: 49062012389.84862| val_0_mse: 45344773973.70184|  0:10:13s\n",
            "epoch 155| loss: 47946175820.09108| val_0_mse: 39974566974.13707|  0:10:17s\n",
            "epoch 156| loss: 46786109555.94831| val_0_mse: 55475624157.64448|  0:10:21s\n",
            "epoch 157| loss: 45529455150.31631| val_0_mse: 58990117291.11761|  0:10:24s\n",
            "epoch 158| loss: 44248591295.09416| val_0_mse: 43522325013.2769|  0:10:28s\n",
            "epoch 159| loss: 43402269672.6843| val_0_mse: 44350296846.03968|  0:10:33s\n",
            "epoch 160| loss: 42393065405.2037| val_0_mse: 44172315860.43138|  0:10:36s\n",
            "epoch 161| loss: 41316789127.64062| val_0_mse: 41447227460.7933|  0:10:40s\n",
            "epoch 162| loss: 40312652708.62768| val_0_mse: 35363965545.30393|  0:10:44s\n",
            "epoch 163| loss: 39357882342.79384| val_0_mse: 36770343242.53251|  0:10:48s\n",
            "epoch 164| loss: 38303120810.61415| val_0_mse: 37151965209.34783|  0:10:53s\n",
            "epoch 165| loss: 37460970708.36184| val_0_mse: 36220589750.60392|  0:10:56s\n",
            "epoch 166| loss: 36612394735.77354| val_0_mse: 36834084198.1235|  0:11:00s\n",
            "epoch 167| loss: 35640161125.61232| val_0_mse: 36253706105.16602|  0:11:04s\n",
            "epoch 168| loss: 34881132807.40429| val_0_mse: 38516554692.59618|  0:11:07s\n",
            "epoch 169| loss: 34054475096.69416| val_0_mse: 35095146602.52069|  0:11:11s\n",
            "epoch 170| loss: 33126666595.40677| val_0_mse: 36862335871.26133|  0:11:15s\n",
            "epoch 171| loss: 32406932343.25662| val_0_mse: 37930940881.27188|  0:11:19s\n",
            "epoch 172| loss: 31717671476.61784| val_0_mse: 27198626987.40559|  0:11:23s\n",
            "epoch 173| loss: 31106970963.65292| val_0_mse: 26920979511.02096|  0:11:27s\n",
            "epoch 174| loss: 30313192451.15077| val_0_mse: 34130762436.14199|  0:11:30s\n",
            "epoch 175| loss: 29647708749.824| val_0_mse: 27783662881.85498|  0:11:34s\n",
            "epoch 176| loss: 29152601404.96738| val_0_mse: 27532235135.96958|  0:11:38s\n",
            "epoch 177| loss: 28228080946.88492| val_0_mse: 36787311781.90621|  0:11:42s\n",
            "epoch 178| loss: 27506917218.46154| val_0_mse: 20229351293.5377|  0:11:45s\n",
            "epoch 179| loss: 26830756768.84676| val_0_mse: 26975892466.06884|  0:11:49s\n",
            "epoch 180| loss: 26426381572.25354| val_0_mse: 25814168099.22238|  0:11:53s\n",
            "epoch 181| loss: 25724003642.44677| val_0_mse: 27776840842.88344|  0:11:57s\n",
            "epoch 182| loss: 25102171672.26092| val_0_mse: 19967345075.05526|  0:12:01s\n",
            "epoch 183| loss: 24702274667.75631| val_0_mse: 28084772450.6926|  0:12:04s\n",
            "epoch 184| loss: 24248683605.07077| val_0_mse: 27250709703.55326|  0:12:08s\n",
            "epoch 185| loss: 23664024528.73846| val_0_mse: 20482608739.4061|  0:12:16s\n",
            "epoch 186| loss: 23095618273.28| val_0_mse: 22665474131.69899|  0:12:22s\n",
            "epoch 187| loss: 22647400343.39446| val_0_mse: 25678214755.28491|  0:12:26s\n",
            "epoch 188| loss: 22116466822.85291| val_0_mse: 23937677509.46288|  0:12:32s\n",
            "epoch 189| loss: 21613089337.65908| val_0_mse: 20176194006.16036|  0:12:38s\n",
            "epoch 190| loss: 21165637844.992| val_0_mse: 20738817407.43763|  0:12:41s\n",
            "epoch 191| loss: 20641196484.45046| val_0_mse: 16688711160.61354|  0:12:45s\n",
            "epoch 192| loss: 20469451997.184| val_0_mse: 22301419664.73951|  0:12:49s\n",
            "epoch 193| loss: 20080682951.28616| val_0_mse: 21953384033.53094|  0:12:53s\n",
            "epoch 194| loss: 19822481512.60553| val_0_mse: 21659815900.95836|  0:12:57s\n",
            "epoch 195| loss: 19468070291.92862| val_0_mse: 19499215823.5875|  0:13:00s\n",
            "epoch 196| loss: 19020458576.34461| val_0_mse: 19322060115.5421|  0:13:04s\n",
            "epoch 197| loss: 18753091164.31754| val_0_mse: 20803461607.44328|  0:13:08s\n",
            "epoch 198| loss: 18429283356.35692| val_0_mse: 18239709572.56308|  0:13:12s\n",
            "epoch 199| loss: 18191499691.24431| val_0_mse: 18317568965.92978|  0:13:16s\n",
            "Stop training because you reached max_epochs = 200 with best_epoch = 191 and best_val_0_mse = 16688711160.61354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print(\"TabNet R²:\", r2_score(y_test, reg.predict(X_test.values)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trWjcErDkWc7",
        "outputId": "5118dd29-82c6-4d06-bc3e-ed9d9144e88e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabNet R²: 0.7805793428622727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Cargar validación\n",
        "val = pd.read_csv('validation.csv')\n",
        "\n",
        "# Columnas categóricas a codificar\n",
        "cat_cols = ['location', 'technology_level']\n",
        "\n",
        "# Encoding (uso el que se entrenó en train)\n",
        "val[cat_cols] = encoder.transform(val[cat_cols])\n",
        "\n",
        "# Seleccionar solo columnas numéricas\n",
        "val_numeric = val.select_dtypes(include=['number'])\n",
        "\n",
        "# Realizar predicciones\n",
        "preds = reg.predict(val_numeric.values).flatten()  # Asegurar 1D si devuelve array 2D\n",
        "\n",
        "# Crear DataFrame final\n",
        "submission = pd.DataFrame({\n",
        "    'id': np.arange(65001, 80001),\n",
        "    'production_rate': preds\n",
        "})"
      ],
      "metadata": {
        "id": "TlFyZzIk5piV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('submission.csv')"
      ],
      "metadata": {
        "id": "vOB4_-HAk8zQ"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}